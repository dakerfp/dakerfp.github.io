<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Daker Pinheiro</title>
    <link>https://dakerfp.com/tags/python/</link>
    <description>Recent content in Python on Daker Pinheiro</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Ⓒ 2017 Daker Fernandes Pinheiro</copyright>
    <lastBuildDate>Sun, 17 Sep 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://dakerfp.com/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Interfacing Keras with tensorflow</title>
      <link>https://dakerfp.com/post/keras-tensorflow/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/keras-tensorflow/</guid>
      <description>Keras is great for machine learning and describing models! However, sometimes it lacks the flexibility power that Tensorflow has. The great news is that you can interface while using Tensorflow as a backend for Keras.
You may for instance, pre-process your data before feeding into a Keras learning model, to use GPUs capabilities with little programming costs. The following example normalizes the channels of a image before training, then it uses the transformed tensor as input to the model.</description>
    </item>
    
    <item>
      <title>Python cookbook: argmin &amp; argmax</title>
      <link>https://dakerfp.com/post/python-argmin-argmax/</link>
      <pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/python-argmin-argmax/</guid>
      <description>def argmin(iter, function): return min((f(x), x) for x in iter)[1] def argmax(iter, function): return max((f(x), x) for x in iter)[1]  &amp;gt;&amp;gt;&amp;gt; argmin(range(-100, 100), lambda x: x * x) 0 &amp;gt;&amp;gt;&amp;gt; argmax(range(-100, 100), lambda x: - x * x) 0 &amp;gt;&amp;gt;&amp;gt; argmax([[1, 2, 4], [1], [2, 5], []], len) [1, 2, 4]  </description>
    </item>
    
    <item>
      <title>PIL -&gt; Pillow</title>
      <link>https://dakerfp.com/post/pil-pillow/</link>
      <pubDate>Thu, 16 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/pil-pillow/</guid>
      <description>Pillow is a PIL fork created to add new features. setuptools support was also added. A more frequent release cycle was also promised. With Pillow you can have PIL as a package dependency in setuptools and virtualenv. That means less clutter and robustness for us.
Pillow allows you to continue to use import PIL, so there is no need to change your current PIL related code. 0 migration overhead.
Archlinux already dropped support for PIL in favor of Pillow.</description>
    </item>
    
    <item>
      <title>Reload and unload modules in Python</title>
      <link>https://dakerfp.com/post/reload-and-unload-modules-in-python/</link>
      <pubDate>Mon, 13 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/reload-and-unload-modules-in-python/</guid>
      <description># python 2.7 import math reload(math) # or import math again to reload the module del(math) # unload module  # python 3.x import math # the reload function was eliminated on python 3 import math # or use exec(&amp;quot;import math&amp;quot;) del(math) # remove module  </description>
    </item>
    
    <item>
      <title>Python cookbook: get the file dir path</title>
      <link>https://dakerfp.com/post/python-cookbook-get-file-dir-path/</link>
      <pubDate>Thu, 09 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/python-cookbook-get-file-dir-path/</guid>
      <description>import os os.path.dirname(os.path.abspath(__file__))  </description>
    </item>
    
    <item>
      <title>Functional Pattern Matching with Python</title>
      <link>https://dakerfp.com/post/functional-pattern-matching-with-python/</link>
      <pubDate>Thu, 03 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/functional-pattern-matching-with-python/</guid>
      <description>This talk as given at Python Brasil 2013, at Brasília.
  Functional Pattern Matching on Python  from Daker Fernandes</description>
    </item>
    
    <item>
      <title>Why is Python slow? Python Nordeste 2013</title>
      <link>https://dakerfp.com/post/why-is-python-slow-python-nordeste-2013/</link>
      <pubDate>Thu, 30 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/why-is-python-slow-python-nordeste-2013/</guid>
      <description>Why is Python slow? Python Nordeste 2013  from Daker Fernandes 
It was a great event! Thanks to everyone who made it happen.</description>
    </item>
    
    <item>
      <title>Raspberry &#43; Python at Python Brasil [8]</title>
      <link>https://dakerfp.com/post/raspberry-python-at-python-brasil-8/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/raspberry-python-at-python-brasil-8/</guid>
      <description>This is the presentation given at Python Brasil [8], in Rio de Janeiro. I hope you like it.
  Raspberry Pi + Python  from Daker Fernandes</description>
    </item>
    
    <item>
      <title>Protein Profile with HMM</title>
      <link>https://dakerfp.com/post/protein_profile_with_hmm/</link>
      <pubDate>Thu, 07 Jul 2011 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/protein_profile_with_hmm/</guid>
      <description>Profinling is the action of summarizing a set of data in a smaller mathematical model. One of the practical usages of profiling techniques is the classification of sequences. With a data set profile, you may calculate the distance of an instance to the model, and classify the instance trough this value.
Profiling proteins is a more specific case of profiling sequences. As we know from the previous post about Hidden Markov Models (HMMs) is a very robust mathematical model to represent probabilistically sequences.</description>
    </item>
    
    <item>
      <title>Optimizing Functions with Python Caching Decorators</title>
      <link>https://dakerfp.com/post/optimizing-functions-with-python-caching-decorators/</link>
      <pubDate>Sat, 11 Jun 2011 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/optimizing-functions-with-python-caching-decorators/</guid>
      <description>On these last months I&amp;rsquo;ve been solving some problems (such as some HMMs algorithms) which the best solutions involves some kind of dynamic programming. Some of them are quite simple to implement, but their recursive formulation are far more intuitive. The problem is that even in functional languages, the recursive functions aren&amp;rsquo;t well handled unless you some mechanism like tail call, which aren&amp;rsquo;t intuitive as we would like to. The simplest example that comes in my mind is the fibonacci function which is usually defined as:</description>
    </item>
    
    <item>
      <title>CpG Islands (3) - Model Evaluation</title>
      <link>https://dakerfp.com/post/cpg-islands-model-evaluation-3/</link>
      <pubDate>Sun, 05 Jun 2011 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/cpg-islands-model-evaluation-3/</guid>
      <description>Following the post we&amp;rsquo;ve built a Hidden Markov Model (HMM) for the CpG islands problem, using the training set. Now we should evaluate if our model is adequate to predict things about CpG islands. For evaluate we may use a tagged sequence and see if the HMM we built can predict the islands and what is it&amp;rsquo;s accuracy.
Using the viterbi path and a tagged sequence (out ouf the training set), enable us to compare if the estimative given by the model is coherent with the real data.</description>
    </item>
    
    <item>
      <title>CpG Islands (2) - Building a Hidden Markov Model</title>
      <link>https://dakerfp.com/post/cpg-islands-model-evaluation-2/</link>
      <pubDate>Thu, 02 Jun 2011 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/cpg-islands-model-evaluation-2/</guid>
      <description>By the definition of the CpG islands in the previous post and the Hidden Markov Models (HMMs) short introduction, we now can model a HMM for finding CpG islands. We can create a model very similar to the &amp;ldquo;Fair Bet Casino&amp;rdquo; problem.
When we are in a nucleotide of given DNA sequence there are two possibilities, that nucleotide belongs to CpG island (lets denote state S1) or do not (S0). If you analyse a sibling nucleotide it can stay in the same state or to change with complementary probabilities.</description>
    </item>
    
    <item>
      <title>Hidden Markov Models</title>
      <link>https://dakerfp.com/post/hidden-markov-models/</link>
      <pubDate>Mon, 30 May 2011 00:00:00 +0000</pubDate>
      
      <guid>https://dakerfp.com/post/hidden-markov-models/</guid>
      <description>Nowadays, many applications use Hidden Markov Models (HMMs) to solve crucial issues such as bioinformatics, speech recognition, musical analysis, digital signal processing, data mining, financial applications, time series analysis and many others. HMMs are probabilistic models which are very useful to model sequence behaviours or discrete time series events. Formally it models Markov processes with hidden states, like an extension for Markov Chains. For computer scientists, is a state machine with probabilistic transitions where each state can emit a value with a given probability.</description>
    </item>
    
  </channel>
</rss>